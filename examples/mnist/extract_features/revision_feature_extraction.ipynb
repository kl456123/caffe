{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# coding: utf-8\n",
    "\n",
    "import numpy as np\n",
    "import caffe\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "# get_ipython().magic(u'matplotlib inline')\n",
    "\n",
    "\n",
    "# set display defaults\n",
    "plt.rcParams['figure.figsize'] = (10, 10)        # large images\n",
    "# don't interpolate: show square pixels\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "# use grayscale output rather than a (potentially misleading) color heatmap\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "\n",
    "caffe.set_mode_cpu()\n",
    "# caffe.set_device(0)\n",
    "\n",
    "\n",
    "def vis_square(data):\n",
    "    \"\"\"Take an array of shape (n, height, width) or (n, height, width, 3)\n",
    "       and visualize each (height, width) thing in a grid of size approx. sqrt(n) by sqrt(n)\"\"\"\n",
    "    # normalize data for display\n",
    "    data = (data - data.min()) / (data.max() - data.min())\n",
    "\n",
    "    # force the number of filters to be square\n",
    "    n = int(np.ceil(np.sqrt(data.shape[0])))\n",
    "    padding = (((0, n ** 2 - data.shape[0]),\n",
    "                (0, 1), (0, 1))                 # add some space between filters\n",
    "               + ((0, 0),) * (data.ndim - 3))  # don't pad the last dimension (if there is one)\n",
    "    data = np.pad(data, padding, mode='constant',\n",
    "                  constant_values=1)  # pad with ones (white)\n",
    "\n",
    "    # tile the filters into an image\n",
    "    data = data.reshape(\n",
    "        (n, n) + data.shape[1:]).transpose((0, 2, 1, 3) + tuple(range(4, data.ndim + 1)))\n",
    "    data = data.reshape(\n",
    "        (n * data.shape[1], n * data.shape[3]) + data.shape[4:])\n",
    "\n",
    "    plt.imshow(data)\n",
    "    plt.axis('off')\n",
    "\n",
    "\n",
    "def get_max_xy(data):\n",
    "    h = data.shape[0]\n",
    "    w = data.shape[1]\n",
    "    idx = data.ravel().argmax()\n",
    "    return idx / w, idx % w\n",
    "\n",
    "\n",
    "def get_net(model_def, model_weights, display=True):\n",
    "    model_def = os.path.abspath(model_def)\n",
    "    model_weights = os.path.abspath(model_weights)\n",
    "\n",
    "    net = caffe.Net(model_def, model_weights, caffe.TEST)\n",
    "    net.forward()\n",
    "    if display:\n",
    "        for layer_name, blob in net.blobs.iteritems():\n",
    "            print layer_name + '\\t' + str(blob.data.shape)\n",
    "    return net\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_feat_by_kernel_spatial_idx(layer_name,\n",
    "                                   img_idx,\n",
    "                                   cls_idx,\n",
    "                                   net,\n",
    "                                   kernel_spatial_idx,\n",
    "                                   group_idx=None,\n",
    "                                   display=True):\n",
    "\n",
    "    layer = net.layer_dict[layer_name]\n",
    "\n",
    "    num_classes = layer.blobs[0].data.shape[0]\n",
    "    assert cls_idx < num_classes,    'cls_idx is out of range,it should be between (0,{:d})'.format(\n",
    "        num_classes - 1)\n",
    "\n",
    "    filters_cls = layer.blobs[0].data[cls_idx]\n",
    "    bias_cls = layer.blobs[1].data[cls_idx]\n",
    "\n",
    "#     filter param\n",
    "    kernel_in_channels = filters_cls.shape[0]\n",
    "    kernel_space_dim = filters_cls.shape[-1] * filters_cls.shape[-2]\n",
    "\n",
    "#     bottom data param\n",
    "    bottom_name = net.bottom_names[layer_name][0]\n",
    "    bottom_shape = net.blobs[bottom_name].data.shape\n",
    "\n",
    "    batch_size = bottom_shape[0]\n",
    "    in_channels = bottom_shape[1]\n",
    "    height = bottom_shape[2]\n",
    "    width = bottom_shape[3]\n",
    "\n",
    "    assert img_idx < batch_size,    'img_idx is out of range,it should be between (0,{:d})'.format(\n",
    "        batch_size - 1)\n",
    "\n",
    "#     so infer ps_group\n",
    "    assert in_channels % kernel_in_channels == 0, 'filter shape error'\n",
    "    ps_group = in_channels / kernel_in_channels\n",
    "\n",
    "\n",
    "#    check if use all in channels or ps_group channels\n",
    "    if kernel_space_dim == ps_group:\n",
    "        ps = True\n",
    "        group_idx = kernel_spatial_idx\n",
    "    else:\n",
    "        ps = False\n",
    "        assert ps_group == 1, 'just support ps_group=1 now'\n",
    "        group_idx = 0\n",
    "\n",
    "    assert group_idx is not None, 'group_idx must be specific in normal model'\n",
    "    assert group_idx < ps_group,    'group_idx is out of range, it should be between (0,{:d})'.format(\n",
    "        ps_group - 1)\n",
    "\n",
    "    conv_g = net.blobs[bottom_name]    .data[img_idx,\n",
    "                                             kernel_in_channels * group_idx:kernel_in_channels * (group_idx + 1)]\n",
    "\n",
    "    conv_g_reshaped = conv_g.reshape((kernel_in_channels, -1))\n",
    "    filters_cls = filters_cls.reshape((kernel_in_channels, -1))\n",
    "    if ps:\n",
    "        filters_cls_g = filters_cls[:, group_idx]\n",
    "    else:\n",
    "        assert kernel_spatial_idx is not None,        'kernel_spatial_idx must be specific in normal model'\n",
    "        filters_cls_g = filters_cls[:, kernel_spatial_idx]\n",
    "\n",
    "    filters_cls_g_reshaped = filters_cls_g.reshape((1, -1))\n",
    "    conv_cls_g = filters_cls_g_reshaped.dot(conv_g_reshaped) + bias_cls\n",
    "\n",
    "    conv_cls_g_reshaped = conv_cls_g.reshape((1, height, width))\n",
    "    if display:\n",
    "        plt.figure(figsize=(2, 2))\n",
    "        vis_square(conv_cls_g_reshaped)\n",
    "    return conv_cls_g_reshaped\n",
    "\n",
    "\n",
    "def get_all_feat_by_kernel_spatial_idx(layer_name,\n",
    "                                       img_idx,\n",
    "                                       cls_idx,\n",
    "                                       net):\n",
    "    weight_shape = net.layer_dict[layer_name].blobs[0].data[cls_idx].shape\n",
    "    kernel_spatial_dim = weight_shape[-1] * weight_shape[-1]\n",
    "    for kernel_spatial_idx in range(kernel_spatial_dim):\n",
    "        get_feat_by_kernel_spatial_idx(layer_name, img_idx, cls_idx, net,\n",
    "                                       kernel_spatial_idx)\n",
    "\n",
    "\n",
    "def out_map_in(spatial_center, kernel_spatial, pad, stride, dilation=1):\n",
    "    # param: kernel_spatial is 2D referring to spatial position\n",
    "\n",
    "    out_h_idx = spatial_center[0]\n",
    "    out_w_idx = spatial_center[1]\n",
    "    in_h_idx = out_h_idx * stride - pad + kernel_spatial[0] * dilation\n",
    "    in_w_idx = out_w_idx * stride - pad + kernel_spatial[1] * dilation\n",
    "    return in_h_idx, in_w_idx\n",
    "\n",
    "\n",
    "def get_next_layer_activated_points(net,\n",
    "                                    layer_name,\n",
    "                                    center,\n",
    "                                    image_idx,\n",
    "                                    pad=0,\n",
    "                                    stride=1,\n",
    "                                    dilation=2, ps=True):\n",
    "\n",
    "    # arg: center is 3D like (c,h,w)\n",
    "    layer = net.layer_dict[layer_name]\n",
    "    bottom_name = net.bottom_names[layer_name][0]\n",
    "#     shape: (c,h,w)\n",
    "    data = net.blobs[bottom_name].data[image_idx]\n",
    "    in_c = data.shape[0]\n",
    "    in_h = data.shape[1]\n",
    "    in_w = data.shape[2]\n",
    "#     params\n",
    "    weights = layer.blobs[0].data\n",
    "#     print weights.shape\n",
    "    bias = layer.blobs[1].data\n",
    "#     print weights.shape\n",
    "    h = weights.shape[-2]\n",
    "    w = weights.shape[-1]\n",
    "    kernel_spatial_dim = h * w\n",
    "#     print kernel_spatial_dim\n",
    "    out_c_idx = center[0]\n",
    "    out_h_idx = center[1]\n",
    "    out_w_idx = center[2]\n",
    "\n",
    "    weights_sliced = weights[out_c_idx]\n",
    "    res = []\n",
    "    for kernel_spatial_idx in range(kernel_spatial_dim):\n",
    "        max_activate_position = []\n",
    "        if ps:\n",
    "            assert in_c % kernel_spatial_dim == 0, 'input channel is not correct'\n",
    "            in_c_per_g = in_c / kernel_spatial_dim\n",
    "            data_sliced = data[in_c_per_g *\n",
    "                               kernel_spatial_idx:in_c_per_g * (kernel_spatial_idx + 1)]\n",
    "        else:\n",
    "            data_sliced = data\n",
    "        kernel_spatial = (kernel_spatial_idx / w, kernel_spatial_idx % w)\n",
    "\n",
    "        in_spatial = out_map_in(center[1:],\n",
    "                                kernel_spatial,\n",
    "                                pad,\n",
    "                                stride,\n",
    "                                dilation)\n",
    "\n",
    "        scores = weights_sliced[:, kernel_spatial_idx / w, kernel_spatial_idx %\n",
    "                                w] * data_sliced[:, in_spatial[0], in_spatial[1]]\n",
    "        in_c_idx = scores.argmax()\n",
    "        if ps:\n",
    "            in_c_idx = in_c_per_g * kernel_spatial_idx + in_c_idx\n",
    "        max_activate_position.append(in_c_idx)\n",
    "        max_activate_position += list(in_spatial)\n",
    "        res.append(max_activate_position)\n",
    "    return res\n",
    "\n",
    "\n",
    "# In[462]:\n",
    "\n",
    "\n",
    "def feat_map_raw(activated_points, feat_map_size, origial_map_size):\n",
    "    scale = np.array(origial_map_size).astype(\n",
    "        np.float) / np.array(feat_map_size)\n",
    "    return np.array(activated_points)[:, 1:] * scale\n",
    "\n",
    "\n",
    "def vis_activated_point(net, activated_points, pixel_val=0.5):\n",
    "    #     note that activated points is 2D (h,w)\n",
    "    data = net.blobs['data'].data[0].copy()\n",
    "    activated_points = list(activated_points)\n",
    "    for origial_activated_point in activated_points:\n",
    "        #         print np.ceil(origial_activated_point[0])\n",
    "        data[:, np.ceil(origial_activated_point[0]).astype(np.int),\n",
    "             np.ceil(origial_activated_point[1]).astype(np.int)]\\\n",
    "            = pixel_val\n",
    "    vis_square(data)\n",
    "\n",
    "\n",
    "def normalize(all_scores, type='relu'):\n",
    "    _sum = 0\n",
    "    all_proportion = []\n",
    "    for idx, score in enumerate(all_scores):\n",
    "        if score < 0 and type == 'relu':\n",
    "            all_scores[idx] = 0\n",
    "            continue\n",
    "        _sum += score\n",
    "    for score in all_scores:\n",
    "        all_proportion.append(1.0 * score / _sum)\n",
    "    return all_proportion\n",
    "\n",
    "\n",
    "def get_part_proportion(layer_name,\n",
    "                        next_activated_points,\n",
    "                        net,\n",
    "                        image_idx,\n",
    "                        cls_idx,\n",
    "                        ps=True):\n",
    "    all_scores = []\n",
    "    layer = net.layer_dict[layer_name]\n",
    "#     params\n",
    "    weights = layer.blobs[0].data\n",
    "    h = weights.shape[-2]\n",
    "    w = weights.shape[-1]\n",
    "    kernel_spatial_dim = h * w\n",
    "    for kernel_spatial_idx in range(kernel_spatial_dim):\n",
    "        if ps:\n",
    "            group_idx = kernel_spatial_idx\n",
    "        else:\n",
    "            group_idx = 0\n",
    "        conv_cls_g_reshaped = get_feat_by_kernel_spatial_idx(layer_name,\n",
    "                                                             image_idx,\n",
    "                                                             cls_idx,\n",
    "                                                             net,\n",
    "                                                             kernel_spatial_idx,\n",
    "                                                             group_idx,\n",
    "                                                             False)\n",
    "        next_activated_point = next_activated_points[kernel_spatial_idx]\n",
    "        all_scores.append(\n",
    "            conv_cls_g_reshaped[0, next_activated_point[-2], next_activated_point[-1]])\n",
    "    return normalize(all_scores), all_scores\n",
    "\n",
    "\n",
    "def help_vis_max_activated_point(net, layer_name, next_activated_points):\n",
    "    #     next_activated_points = get_next_layer_max_xy(net,'conv5',center,0)\n",
    "    feat_map_size = net.blobs[layer_name].data.shape[2:]\n",
    "    origial_map_size = net.blobs['data'].data.shape[2:]\n",
    "    origial_activated_points = feat_map_raw(next_activated_points,\n",
    "                                            feat_map_size,\n",
    "                                            origial_map_size)\n",
    "    vis_activated_point(net, origial_activated_points)\n",
    "\n",
    "\n",
    "# test_net4()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_net3():\n",
    "    model_def = './PSConv_lenet_train_test.prototxt'\n",
    "    model_weights = 'PSConv/PSConv_lenet__iter_20000.caffemodel'\n",
    "\n",
    "    net3 = get_net(model_def, model_weights)\n",
    "\n",
    "    # first image to test\n",
    "    img_idx = 0\n",
    "    # first label corresponding to the image\n",
    "    cls_idx = 7\n",
    "    # the last conv layer\n",
    "    layer_name = 'conv5'\n",
    "    \n",
    "    print 'separate feature visualization'\n",
    "    get_all_feat_by_kernel_spatial_idx(layer_name,\n",
    "                                       img_idx,\n",
    "                                       cls_idx,\n",
    "                                       net3)\n",
    "    cls_idx = 7\n",
    "    center = []\n",
    "    center.append(cls_idx)\n",
    "    center += list(\n",
    "        get_max_xy(net3.blobs[layer_name].data[img_idx, cls_idx]))\n",
    "\n",
    "    # print center\n",
    "    next_activated_points = get_next_layer_activated_points(net3,\n",
    "                                                            layer_name,\n",
    "                                                            center,\n",
    "                                                            0)\n",
    "    # print next_activated_points\n",
    "#     feat_map_size = net3.blobs['conv4'].data.shape[2:]\n",
    "#     origial_map_size = net3.blobs['data'].data.shape[2:]\n",
    "#     origial_activated_points = feat_map_raw(next_activated_points,\n",
    "#                                             feat_map_size,\n",
    "#                                             origial_map_size)\n",
    "\n",
    "#     vis_activated_point(net3, origial_activated_points)\n",
    "    \n",
    "    help_vis_max_activated_point(net3,\n",
    "                                 layer_name, \n",
    "                                 next_activated_points)\n",
    "    pad = 0\n",
    "    stride = 2\n",
    "    dilation = 1\n",
    "#     for next_activated_point in next_activated_points:\n",
    "#         print get_next_layer_activated_points(net3, 'conv4', next_activated_point, 0, pad, stride, dilation)\n",
    "\n",
    "#     print next_activated_points\n",
    "\n",
    "    get_all_feat_by_kernel_spatial_idx('conv5', 0, 7, net3)\n",
    "\n",
    "    all_proportion, all_scores = get_part_proportion('conv5',\n",
    "                                                     next_activated_points,\n",
    "                                                     net3,\n",
    "                                                     img_idx,\n",
    "                                                     cls_idx,\n",
    "                                                     ps=True)\n",
    "    print all_proportion\n",
    "    print sum(all_scores)\n",
    "\n",
    "#     net3.blobs['conv5'].data[0, 7]\n",
    "\n",
    "#     get_all_feat_by_kernel_spatial_idx('conv4', 0, 79, net3)\n",
    "\n",
    "#     get_all_feat_by_kernel_spatial_idx('conv4', 0, 128, net3)\n",
    "\n",
    "#     get_all_feat_by_kernel_spatial_idx('conv4', 0, 262, net3)\n",
    "\n",
    "#     print center"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_net3()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAD7CAYAAABKWyniAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7efd6bc0b3d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "vis_square(net3.blobs['conv5'].data[0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAD8CAYAAABXXhlaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7efd6be18410>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "vis_square(net3.blobs['data'].data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_net4():\n",
    "    model_def = '../Conv_lenet_train_test.prototxt'\n",
    "    model_weights = '../temp/Conv_lenet_8_iter_20000.caffemodel'\n",
    "    net4 = get_net(model_def, model_weights)\n",
    "    layer_name = 'conv5'\n",
    "    img_idx = 0\n",
    "\n",
    "    vis_square(net4.blobs['conv5'].data[img_idx, :])\n",
    "    get_all_feat_by_kernel_spatial_idx('conv5', 0, 7, net4)\n",
    "\n",
    "    cls_idx = 7\n",
    "    center = []\n",
    "    center.append(cls_idx)\n",
    "    center += list(get_max_xy(net4.blobs[layer_name].data[0, 7]))\n",
    "    print center\n",
    "    next_activated_points = get_next_layer_activated_points(net4,\n",
    "                                                            layer_name,\n",
    "                                                            center,\n",
    "                                                            img_idx,\n",
    "                                                            ps=False)\n",
    "    print next_activated_points\n",
    "    all_proportion, all_scores = get_part_proportion(layer_name,\n",
    "                                                     next_activated_points,\n",
    "                                                     net4,\n",
    "                                                     img_idx,\n",
    "                                                     cls_idx,\n",
    "                                                     ps=False)\n",
    "    print all_proportion\n",
    "    print sum(all_scores)\n",
    "    print net4.blobs['conv5'].data[0, 7]\n",
    "    vis_square(net4.blobs['conv5'].data[0])\n",
    "\n",
    "    help_vis_max_activated_point(net4, 'conv4', next_activated_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_net4_v1():\n",
    "    model_def = 'Conv_lenet_train_test.prototxt'\n",
    "    model_weights = 'Conv/Conv_lenet__iter_20000.caffemodel'\n",
    "\n",
    "    net4 = get_net(model_def, model_weights)\n",
    "    cls_idx = 7\n",
    "    layer_name = 'conv5'\n",
    "    center = []\n",
    "    center.append(cls_idx)\n",
    "    center+=list(get_max_xy(net4.blobs['conv5'].data[0,7]))\n",
    "    # print center\n",
    "    next_activated_points = get_next_layer_activated_points(net4,'conv5',center,0)\n",
    "    # print next_activated_points\n",
    "    help_vis_max_activated_point(net4, layer_name, next_activated_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_net4_v1()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
